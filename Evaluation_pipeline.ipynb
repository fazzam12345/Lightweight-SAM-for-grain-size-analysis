{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f592a1",
   "metadata": {},
   "source": [
    "\n",
    "# Comparative Study of Segment Anything Models for Grain Size Analysis: One Step Towards Automation\n",
    "\n",
    "This notebook demonstrates the core workflow for automating grain size distribution analysis in petrographic images using a lightweight variant of the Segment Anything Model (SAM). Specifically, it is configured to run using **MobileSAM as an example**.\n",
    "\n",
    "This code accompanies the publication \"Comparative Study of Segment Anything Models for Grain Size Analysis: One Step Towards Automation\" and is provided for code availability and reproducibility.\n",
    "\n",
    "The notebook covers:\n",
    "1.  Setting up the environment and configuring model loading.\n",
    "2.  Loading the selected SAM model variant and an example petrographic image.\n",
    "3.  Performing automatic mask generation using the SAM variant.\n",
    "4.  Visualizing the generated masks and contours.\n",
    "5.  Processing the detected masks to extract grain parameters (area, length, width, perimeter).\n",
    "6.  Loading ground truth annotations.\n",
    "7.  Matching predicted grains to ground truth annotations for segmentation performance evaluation (Precision, Recall, F1-score).\n",
    "8.  Analyzing and visualizing grain size distributions derived from the model predictions compared to ground truth.\n",
    "9.  Saving evaluation metrics and distribution data.\n",
    "\n",
    "**Prerequisites:**\n",
    "*   Python 3.x\n",
    "*   Required libraries: `torch`, `torchvision`, `numpy`, `matplotlib`, `opencv-python`, `pandas`, `scipy`, `scikit-learn`, `openpyxl`. Install using pip: `pip install torch torchvision numpy matplotlib opencv-python pandas scipy scikit-learn openpyxl`\n",
    "*   **SAM Model Libraries:** You need the specific library or code for the SAM variant you wish to use.\n",
    "    *   For original SAM (ViT-H/L/B): Install `segment_anything` (`pip install segment_anything`).\n",
    "    *   For MobileSAM: Install `mobile_sam` (`pip install git+https://github.com/ChaoningZhang/MobileSAM.git`).\n",
    "    *   For other variants (SlimSAM, TinySAM, RepViT-SAM, FastSAM), you might need to clone their specific repositories and potentially add them to your `sys.path`.\n",
    "*   **Pre-trained Checkpoints:** Download the checkpoint file (`.pt` or `.pth`) for the specific SAM variant you intend to use.\n",
    "*   **Data Files:** Provide your example image file and its corresponding ground truth annotation file (expected in a JSON format matching the structure defined in the `get_sam_annotations_from_masks` function or adapted as needed).\n",
    "\n",
    "Please ensure necessary libraries are installed, checkpoints are downloaded, and data files are placed in appropriate locations relative to this notebook or update the paths below accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefa5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import xml.etree.ElementTree as ET # Keep in case XML annotation format is needed later, but JSON is used below.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import necessary components for specific SAM variants\n",
    "# NOTE: You might need to adjust these imports and potentially add sys.path adjustments\n",
    "# depending on how you installed or structured the code for different SAM variants.\n",
    "# This example primarily uses imports compatible with the 'mobile_sam' library structure.\n",
    "try:\n",
    "    # Attempt to import from mobile_sam\n",
    "    from mobile_sam.modeling import sam_model_registry as mobile_sam_model_registry\n",
    "    from mobile_sam import SamAutomaticMaskGenerator as MobileSamAutomaticMaskGenerator\n",
    "    # from mobile_sam import SamPredictor # Not used in this automatic mask generation flow\n",
    "    print(\"Successfully imported MobileSAM components.\")\n",
    "    MOBILE_SAM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"MobileSAM components not found. Please install: pip install git+https://github.com/ChaoningZhang/MobileSAM.git\")\n",
    "    MOBILE_SAM_AVAILABLE = False\n",
    "    mobile_sam_model_registry = None\n",
    "    MobileSamAutomaticMaskGenerator = None\n",
    "\n",
    "# You might need similar try-except blocks or conditional imports for other variants\n",
    "# Example (conceptual, requires 'segment-anything' installed):\n",
    "# try:\n",
    "#     from segment_anything import sam_model_registry as generic_sam_model_registry\n",
    "#     from segment_anything import SamAutomaticMaskGenerator as GenericSamAutomaticMaskGenerator\n",
    "#     print(\"Successfully imported standard SAM components.\")\n",
    "#     GENERIC_SAM_AVAILABLE = True\n",
    "# except ImportError:\n",
    "#     print(\"Standard SAM components not found. Please install: pip install segment_anything\")\n",
    "#     GENERIC_SAM_AVAILABLE = False\n",
    "#     generic_sam_model_registry = None\n",
    "#     GenericSamAutomaticMaskGenerator = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1d4ad",
   "metadata": {},
   "source": [
    "# Configuration and Setup\n",
    "\n",
    "Define model variant, paths, and parameters.\n",
    "\n",
    "**To use a different SAM variant:**\n",
    "1.  Change the `MODEL_VARIANT` string.\n",
    "2.  Update the `CHECKPOINT_PATH` to point to the correct model file.\n",
    "3.  **Crucially**, modify the \"Load Model and Image\" cell below to correctly load the model using the specific library/code for that variant. The import mechanism (`sam_model_registry`, `SamAutomaticMaskGenerator` class name, required arguments) may differ between variants.\n",
    "4.  The `AMBG_PARAMS` dictionary might need tuning for optimal performance with the chosen model variant and image type, although the parameter names should be consistent if the `SamAutomaticMaskGenerator` interface is maintained.\n",
    "5.  Ensure the necessary library/code for the chosen variant is installed and accessible. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e222a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# Model variant selection (Choose one)\n",
    "MODEL_VARIANT = \"MobileSAM\"\n",
    "# MODEL_VARIANT = \"SAM-ViT-H\" # Example for original SAM, requires code changes below\n",
    "\n",
    "# Paths\n",
    "# Adjust these paths based on your file structure and chosen model/data\n",
    "if MODEL_VARIANT == \"MobileSAM\":\n",
    "    CHECKPOINT_PATH = \"../weights/mobile_sam.pt\"\n",
    "    MODEL_TYPE = \"vit_t\" # Specific model type string for MobileSAM registry\n",
    "    SamAutomaticMaskGeneratorClass = MobileSamAutomaticMaskGenerator\n",
    "    sam_model_registry_func = mobile_sam_model_registry\n",
    "elif MODEL_VARIANT == \"SAM-ViT-H\":\n",
    "    # Example for original SAM - requires 'segment-anything' library\n",
    "    # If using this, uncomment imports for generic_sam_model_registry and GenericSamAutomaticMaskGenerator\n",
    "    # and ensure the library is installed.\n",
    "    # CHECKPOINT_PATH = \"../weights/sam_vit_h.pth\" # Example path for ViT-H\n",
    "    # MODEL_TYPE = \"vit_h\" # Specific model type string for standard SAM registry\n",
    "    # SamAutomaticMaskGeneratorClass = GenericSamAutomaticMaskGenerator\n",
    "    # sam_model_registry_func = generic_sam_model_registry\n",
    "    # print(\"NOTE: Loading SAM-ViT-H requires the 'segment-anything' library and adjusting imports/paths.\")\n",
    "    # raise NotImplementedError(f\"Configuration for {MODEL_VARIANT} is not fully implemented in this example.\")\n",
    "    pass # Placeholder - replace with actual config if enabling\n",
    "\n",
    "# --- Add elif blocks here for other variants (SlimSAM, TinySAM, RepViT-SAM, FastSAM) ---\n",
    "# Each variant might require different imports, model_type strings, or loading functions.\n",
    "# Example (Conceptual for SlimSAM):\n",
    "# elif MODEL_VARIANT == \"SlimSAM\":\n",
    "#    # Requires SlimSAM specific library/repo\n",
    "#    # from slim_sam import sam_model_registry_slim, SamAutomaticMaskGenerator_slim\n",
    "#    # CHECKPOINT_PATH = \"../weights/slim_sam.pt\"\n",
    "#    # MODEL_TYPE = \"vit_t_slim\" # Example model type string\n",
    "#    # SamAutomaticMaskGeneratorClass = SamAutomaticMaskGenerator_slim\n",
    "#    # sam_model_registry_func = sam_model_registry_slim\n",
    "#    pass # Placeholder\n",
    "\n",
    "\n",
    "else:\n",
    "     raise ValueError(f\"Unknown MODEL_VARIANT: {MODEL_VARIANT}. Please choose a valid option and configure paths/loading.\")\n",
    "\n",
    "\n",
    "# Data Paths\n",
    "EXAMPLE_IMAGE_PATH = \"../images/nanoprecvpitate.png\" # Path to the example image\n",
    "GROUND_TRUTH_ANNOTATION_PATH = \"../annotation/nanoprecvpit.json\" # Path to the ground truth JSON file\n",
    "OUTPUT_RESULTS_DIR = f\"../results/{MODEL_VARIANT.lower()}_example\" # Directory to save results (variant specific)\n",
    "\n",
    "# Image specific settings (adjust for your image)\n",
    "# Scale factor to convert pixels to real-world units (e.g., micrometers per pixel)\n",
    "# Example: if 100 pixels = 225 micrometers, scale_factor = 225 / 100 = 2.25\n",
    "SCALE_FACTOR = 2.25\n",
    "\n",
    "# Automatic mask generation parameters (adjust for your image and chosen model variant)\n",
    "# These parameters control the density of points sampled, thresholds for masks, etc.\n",
    "# Optimal values *may* vary between different SAM model variants.\n",
    "# Refer to SAM documentation for detailed explanation of each parameter.\n",
    "AMBG_PARAMS = {\n",
    "    \"points_per_side\": 32, # Number of points sampled per side of the image grid\n",
    "    \"points_per_batch\": 16, # How many point prompts are processed simultaneously\n",
    "    \"pred_iou_thresh\": 0.92, # Threshold on the model's own mask quality prediction\n",
    "    \"stability_score_thresh\": 0.95, # Additional threshold on mask stability\n",
    "    \"min_mask_region_area\": 100, # Minimum area in pixels for a mask to be kept\n",
    "    \"crop_n_layers\": 1, # Number of layers of image cropping to use\n",
    "    \"crop_n_points_downscale_factor\": 1, # Downscaling factor for points within crops\n",
    "    # Add other parameters as needed, e.g., \"box_nms_thresh\", \"crop_overlap_ratio\", etc.\n",
    "    # Example: Smaller min_mask_region_area might be needed for very fine grains,\n",
    "    # but can increase noise (false positives).\n",
    "}\n",
    "\n",
    "# Evaluation settings\n",
    "IOU_THRESHOLD = 0.5 # IoU threshold for matching predicted masks to ground truth\n",
    "CENTROID_MATCH_DISTANCE = 100 # Maximum pixel distance for a match candidate\n",
    "\n",
    "# Device setup\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Setup ---\n",
    "print(f\"Selected Model Variant: {MODEL_VARIANT}\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {OUTPUT_RESULTS_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9e13c",
   "metadata": {},
   "source": [
    "\n",
    "# Load Model and Image\n",
    "\n",
    "Load the selected SAM model variant and the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the selected SAM model\n",
    "print(f\"Loading {MODEL_VARIANT} model from {CHECKPOINT_PATH}...\")\n",
    "\n",
    "if MODEL_VARIANT == \"MobileSAM\":\n",
    "    if not MOBILE_SAM_AVAILABLE:\n",
    "         raise RuntimeError(\"MobileSAM variant selected but components not imported. Check installation.\")\n",
    "    if not os.path.exists(CHECKPOINT_PATH):\n",
    "         raise FileNotFoundError(f\"MobileSAM checkpoint not found at {CHECKPOINT_PATH}. Please download it.\")\n",
    "\n",
    "    sam = sam_model_registry_func[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "\n",
    "# --- Add elif blocks here for loading other variants ---\n",
    "# Example (Conceptual for SAM-ViT-H):\n",
    "# elif MODEL_VARIANT == \"SAM-ViT-H\":\n",
    "#     if not GENERIC_SAM_AVAILABLE:\n",
    "#          raise RuntimeError(\"SAM-ViT-H variant selected but components not imported. Check installation.\")\n",
    "#     if not os.path.exists(CHECKPOINT_PATH):\n",
    "#          raise FileNotFoundError(f\"SAM-ViT-H checkpoint not found at {CHECKPOINT_PATH}. Please download it.\")\n",
    "#     sam = sam_model_registry_func[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "# elif MODEL_VARIANT == \"SlimSAM\":\n",
    "#     # Add SlimSAM loading logic based on its library\n",
    "#     pass # Placeholder\n",
    "\n",
    "else:\n",
    "     # This else should ideally not be reached if the config block validated MODEL_VARIANT,\n",
    "     # but it's here as a safeguard.\n",
    "     raise RuntimeError(f\"Loading logic for MODEL_VARIANT: {MODEL_VARIANT} is not implemented.\")\n",
    "\n",
    "sam.to(device=DEVICE)\n",
    "sam.eval()\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Load Image\n",
    "print(f\"Loading image from {EXAMPLE_IMAGE_PATH}...\")\n",
    "if not os.path.exists(EXAMPLE_IMAGE_PATH):\n",
    "    raise FileNotFoundError(f\"The image file was not found at {EXAMPLE_IMAGE_PATH}. Please check the path.\")\n",
    "\n",
    "image_bgr = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
    "if image_bgr is None:\n",
    "     raise IOError(f\"Could not read image file at {EXAMPLE_IMAGE_PATH}\")\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "image_width = image_rgb.shape[1]\n",
    "image_height = image_rgb.shape[0]\n",
    "print(f\"Image loaded: {image_width}x{image_height} pixels.\")\n",
    "\n",
    "# Note: The SamAutomaticMaskGenerator interface across SAM variants generally\n",
    "# expects a HxWx3 NumPy array (uint8). We will use the `image_rgb` NumPy array directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374b032",
   "metadata": {},
   "source": [
    "\n",
    "# Define Helper Functions\n",
    "\n",
    "These functions are used for visualization, mask processing, and evaluation. They operate on standard data structures (NumPy arrays, lists of dictionaries) and should generally work regardless of the SAM variant used for mask generation, as long as the output format of `SamAutomaticMaskGenerator.generate()` is consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (Keep all helper functions as they were in the previous cleaned version:\n",
    "# show_anns, draw_mask_contours, compute_length_width_feret,\n",
    "# get_sam_annotations_from_masks, create_mask_from_polygon_batch,\n",
    "# calculate_centroids, fast_match_grains, calculate_metrics,\n",
    "# draw_matched_and_unmatched, analyze_grain_distributions,\n",
    "# calculate_cumulative_data, evaluate_distribution_similarity)\n",
    "# --- Paste the code for all helper functions here ---\n",
    "def show_anns(anns):\n",
    "    \"\"\"Displays segmentation masks from SAM on the current matplotlib axes.\"\"\"\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    # Sort masks by area for consistent layering (largest underneath)\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    # Create a transparent overlay image\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4), dtype=np.uint8) * 255 # Start with white, not black\n",
    "    img[:,:,3] = 0 # Set alpha channel to 0 (fully transparent)\n",
    "\n",
    "    # Draw each mask with a random color and fixed transparency\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.random.randint(0, 256, 3)\n",
    "        # Apply color to the mask area\n",
    "        img[m] = [*color_mask, 150] # Use 150 alpha for semi-transparency\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "def draw_mask_contours(image: np.ndarray, masks: List[Dict], color: Tuple[int, int, int] = (0, 255, 0), thickness: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draws contours of masks on the input image.\n",
    "\n",
    "    Args:\n",
    "        image: The input image (NumPy array, HxWx3, BGR or RGB).\n",
    "        masks: A list of mask dictionaries from SAM.\n",
    "        color: The color for the contours (BGR tuple).\n",
    "        thickness: The thickness of the contours.\n",
    "\n",
    "    Returns:\n",
    "        A copy of the image with contours drawn.\n",
    "    \"\"\"\n",
    "    # Ensure image is in BGR format for OpenCV drawing\n",
    "    # Simple heuristic: check if max value is 255 and min is 0, and if sum of first pixel is high (likely color)\n",
    "    is_rgb = image.shape[-1] == 3 and np.max(image) > 1 and np.min(image) >= 0 and image[0,0,:].sum() > 100 # Avoid grayscale sum=0\n",
    "    if is_rgb:\n",
    "         result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    elif image.shape[-1] == 3: # It's a 3-channel image, assume BGR if not RGB by heuristic\n",
    "         result = image.copy()\n",
    "    else: # Grayscale or other format\n",
    "         result = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) # Convert grayscale to BGR\n",
    "\n",
    "\n",
    "    for mask in masks:\n",
    "        # Get the mask segmentation directly\n",
    "        binary_mask = mask['segmentation'].astype(np.uint8)\n",
    "\n",
    "        # Find contours (RETR_EXTERNAL retrieves only outer contours)\n",
    "        # CHAIN_APPROX_SIMPLE compresses horizontal, vertical, and diagonal segments\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw contours\n",
    "        cv2.drawContours(result, contours, -1, color, thickness) # -1 draws all contours found\n",
    "\n",
    "    # Convert back to RGB if the input was RGB\n",
    "    if is_rgb:\n",
    "         return cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "         return result # Return as BGR or grayscale-converted BGR\n",
    "\n",
    "\n",
    "def compute_length_width_feret(contour: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Computes the maximum and minimum Feret diameters (approximated length and width).\n",
    "\n",
    "    Args:\n",
    "        contour: A single contour as a NumPy array (Nx1x2).\n",
    "\n",
    "    Returns:\n",
    "        A tuple (max_feret_diameter, min_feret_diameter). Returns (0.0, 0.0) for invalid contours.\n",
    "    \"\"\"\n",
    "    if len(contour) < 3:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    try:\n",
    "        # Get convex hull\n",
    "        hull = cv2.convexHull(contour)\n",
    "\n",
    "        # Find minimum area bounding rectangle\n",
    "        rect = cv2.minAreaRect(hull)\n",
    "        (center_x, center_y), (width, height), angle = rect\n",
    "\n",
    "        # The sides of the min area rectangle approximate Feret diameters\n",
    "        # Length is typically the longer side, width is the shorter\n",
    "        length = max(width, height)\n",
    "        width = min(width, height)\n",
    "\n",
    "        return float(length), float(width) # Ensure float return type\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing Feret diameters for contour: {e}\")\n",
    "        return 0.0, 0.0 # Return zero if calculation fails\n",
    "\n",
    "\n",
    "def get_sam_annotations_from_masks(masks: List[Dict], scale_factor: float, image_width: int, image_height: int, coverage_threshold: float = 0.95) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes SAM masks to extract grain properties and formats them as annotations.\n",
    "\n",
    "    Args:\n",
    "        masks: A list of mask dictionaries from SAM.\n",
    "        scale_factor: Factor to convert pixels to real-world units.\n",
    "        image_width: Width of the original image in pixels.\n",
    "        image_height: Height of the original image in pixels.\n",
    "        coverage_threshold: Exclude masks covering more than this fraction of the image area.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, where each dictionary represents a detected grain with its properties.\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    print(f\"Processing {len(masks)} SAM masks...\")\n",
    "\n",
    "    for i, mask_data in enumerate(masks):\n",
    "        mask = mask_data.get('segmentation')\n",
    "        if mask is None:\n",
    "             print(f\"Warning: Mask {i} missing 'segmentation' key. Skipping.\")\n",
    "             continue\n",
    "\n",
    "        # Calculate mask area in pixels\n",
    "        # Use area provided by SAM if available, otherwise calculate from mask\n",
    "        mask_area_pixels = mask_data.get('area', np.sum(mask.astype(np.uint8)))\n",
    "\n",
    "\n",
    "        # Calculate coverage\n",
    "        # Handle potential division by zero if image area is 0 (shouldn't happen with valid image)\n",
    "        mask_coverage = mask_area_pixels / total_image_area if total_image_area > 0 else 0.0\n",
    "\n",
    "\n",
    "        # Skip masks that cover more than the threshold (likely background/large features)\n",
    "        if mask_coverage >= coverage_threshold:\n",
    "            # print(f\"Skipping mask {i} due to large coverage ({mask_coverage:.2f})\")\n",
    "            continue\n",
    "\n",
    "        # Convert mask to contours\n",
    "        # cv2.findContours expects a binary mask (0 and >0, typically 0 and 255 or 0 and 1)\n",
    "        # Ensure the mask is boolean or already uint8 0/255\n",
    "        if mask.dtype == bool:\n",
    "             binary_mask = mask.astype(np.uint8) * 255 # Convert boolean mask to uint8 with values 0 and 255\n",
    "        elif mask.dtype == np.uint8 and np.max(mask) <= 1:\n",
    "             binary_mask = mask * 255 # Convert 0/1 uint8 to 0/255\n",
    "        else:\n",
    "             binary_mask = mask.astype(np.uint8) # Assume it's already in a usable format\n",
    "\n",
    "        # Handle potential empty masks after thresholding or conversion\n",
    "        if np.sum(binary_mask) == 0:\n",
    "             # print(f\"Warning: Binary mask for mask {i} is empty after processing.\")\n",
    "             continue\n",
    "\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Process each contour found within the mask\n",
    "        # SAM masks are typically single objects, so usually only one contour per mask\n",
    "        for contour in contours:\n",
    "             # Filter out tiny contours that might be artifacts even after min_mask_region_area filtering\n",
    "             # Check if the calculated area is less than a fraction of the min_mask_region_area param\n",
    "             if cv2.contourArea(contour) < AMBG_PARAMS.get(\"min_mask_region_area\", 0) * 0.1: # Use a small tolerance\n",
    "                  # print(f\"Skipping tiny contour with area {cv2.contourArea(contour)}.\")\n",
    "                  continue\n",
    "             \n",
    "             # Ensure contour has enough points for polygon representation\n",
    "             if len(contour) < 3:\n",
    "                 # print(f\"Skipping contour with only {len(contour)} points.\")\n",
    "                 continue\n",
    "\n",
    "             # Format contour to list of (x,y) tuples for storage\n",
    "             segmentation = [pt[0].tolist() for pt in contour] # Convert numpy int32 to standard Python int/float\n",
    "\n",
    "             # Calculate area and true area\n",
    "             # Using cv2.contourArea for consistency with contour processing\n",
    "             area_pixels = cv2.contourArea(contour)\n",
    "             area_true = area_pixels * (scale_factor**2)\n",
    "\n",
    "             # Calculate length and width using Feret diameter approximation\n",
    "             length_pixels, width_pixels = compute_length_width_feret(contour)\n",
    "             length_true = length_pixels * scale_factor\n",
    "             width_true = width_pixels * scale_factor\n",
    "\n",
    "             # Calculate perimeter and true perimeter\n",
    "             perimeter_pixels = cv2.arcLength(contour, True) # True indicates the contour is closed\n",
    "             perimeter_true = perimeter_pixels * scale_factor\n",
    "\n",
    "             annotations.append({\n",
    "                 \"grain_id\": len(annotations) + 1, # Assign unique ID\n",
    "                 \"pixel_coords\": segmentation,\n",
    "                 \"area_pixels\": float(area_pixels), # Ensure float\n",
    "                 \"area_true\": float(area_true), # Ensure float\n",
    "                 \"length_pixels\": float(length_pixels), # Ensure float\n",
    "                 \"length_true\": float(length_true), # Ensure float\n",
    "                 \"width_pixels\": float(width_pixels), # Ensure float\n",
    "                 \"width_true\": float(width_true), # Ensure float\n",
    "                 \"perimeter_pixels\": float(perimeter_pixels), # Ensure float\n",
    "                 \"perimeter_true\": float(perimeter_true) # Ensure float\n",
    "             })\n",
    "\n",
    "    print(f\"Extracted properties for {len(annotations)} potential grains.\")\n",
    "    return annotations\n",
    "\n",
    "def create_mask_from_polygon_batch(polygons: List, width: int, height: int) -> np.ndarray:\n",
    "    \"\"\"Creates binary masks from a list of polygon coordinates.\"\"\"\n",
    "    if not polygons:\n",
    "        return np.zeros((0, height, width), dtype=np.uint8) # Return empty array if no polygons\n",
    "\n",
    "    # Ensure polygons are in the correct format (list of np arrays or similar)\n",
    "    # and handle potential empty polygons\n",
    "    valid_polygons = []\n",
    "    for poly in polygons:\n",
    "        try:\n",
    "            poly_np = np.array(poly, dtype=np.int32).reshape((-1, 1, 2))\n",
    "            if poly_np.shape[0] >= 3: # Check if polygon has at least 3 points\n",
    "                valid_polygons.append(poly_np)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process polygon points: {poly}. Error: {e}\")\n",
    "\n",
    "\n",
    "    if not valid_polygons:\n",
    "         return np.zeros((0, height, width), dtype=np.uint8) # Return empty if no valid polygons\n",
    "\n",
    "    masks = np.zeros((len(valid_polygons), height, width), dtype=np.uint8)\n",
    "    for i, polygon_pts in enumerate(valid_polygons):\n",
    "        try:\n",
    "            cv2.fillPoly(masks[i], [polygon_pts], 1)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not fill polygon {polygon_pts}. Error: {e}\")\n",
    "            masks[i] = 0 # Ensure the mask remains zero for this invalid polygon\n",
    "            \n",
    "    return masks\n",
    "\n",
    "\n",
    "def calculate_centroids(polygons: List) -> np.ndarray:\n",
    "    \"\"\"Calculate centroids for all polygons.\"\"\"\n",
    "    centroids = []\n",
    "    for poly in polygons:\n",
    "        # Ensure poly is a numpy array for mean calculation\n",
    "        try:\n",
    "            poly_np = np.array(poly)\n",
    "            if poly_np.ndim == 2 and poly_np.shape[0] > 0 and np.isfinite(poly_np).all():\n",
    "                 centroids.append(np.mean(poly_np, axis=0))\n",
    "            else:\n",
    "                 centroids.append([np.nan, np.nan]) # Append NaN for invalid polygons\n",
    "                 # print(f\"Warning: Skipping centroid for invalid polygon data: {poly}\")\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error processing polygon {poly} for centroid: {e}\")\n",
    "             centroids.append([np.nan, np.nan]) # Append NaN on error\n",
    "\n",
    "\n",
    "    return np.array(centroids) if centroids else np.array([])\n",
    "\n",
    "\n",
    "def fast_match_grains(gt_grains: List[Dict], all_pred_grains: List[Dict],\n",
    "                     image_width: int, image_height: int,\n",
    "                     iou_threshold: float = 0.5,\n",
    "                     max_distance: float = 100) -> Tuple[Dict, Dict, List]:\n",
    "    \"\"\"\n",
    "    Match predicted grains to ground truth grains based on centroid proximity and IoU.\n",
    "    Tracks all predictions to correctly calculate False Positives.\n",
    "\n",
    "    Args:\n",
    "        gt_grains: List of ground truth grain dictionaries. Must have 'grain_id' and 'pixel_coords'.\n",
    "        all_pred_grains: List of ALL predicted grain dictionaries. Must have 'pixel_coords'.\n",
    "        image_width: Width of the image.\n",
    "        image_height: Height of the image.\n",
    "        iou_threshold: Minimum IoU for a match.\n",
    "        max_distance: Maximum centroid distance for a match candidate.\n",
    "\n",
    "    Returns:\n",
    "        A tuple:\n",
    "        - matches: Dict mapping GT grain_id to the original index in all_pred_grains.\n",
    "        - matched_pred_data: Dict mapping original pred_grain_index to simplified prediction data.\n",
    "        - unmatched_preds: List of prediction dictionaries that were not matched.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to match {len(gt_grains)} ground truth grains with {len(all_pred_grains)} predictions...\")\n",
    "\n",
    "    if not gt_grains or not all_pred_grains:\n",
    "        print(\"Warning: No ground truth or predictions to match.\")\n",
    "        return {}, {}, all_pred_grains # Return empty results, all preds are unmatched if no GT\n",
    "\n",
    "\n",
    "    # Extract polygons and calculate centroids\n",
    "    # Filter out GT grains missing required data before processing\n",
    "    valid_gt_grains = [g for g in gt_grains if g.get('grain_id') is not None and g.get('pixel_coords') is not None and len(g.get('pixel_coords', [])) >= 3]\n",
    "    if len(valid_gt_grains) != len(gt_grains):\n",
    "         print(f\"Warning: Skipped {len(gt_grains) - len(valid_gt_grains)} ground truth grains due to missing data or invalid polygons.\")\n",
    "    gt_polygons = [g['pixel_coords'] for g in valid_gt_grains]\n",
    "    gt_ids = [g['grain_id'] for g in valid_gt_grains]\n",
    "\n",
    "\n",
    "    # Filter out predictions missing required data before processing\n",
    "    valid_pred_indices = [i for i, p in enumerate(all_pred_grains) if p.get('pixel_coords') is not None and len(p.get('pixel_coords', [])) >= 3]\n",
    "    if len(valid_pred_indices) != len(all_pred_grains):\n",
    "         print(f\"Warning: Skipped {len(all_pred_grains) - len(valid_pred_indices)} predictions due to missing data or invalid polygons.\")\n",
    "\n",
    "    valid_pred_grains = [all_pred_grains[i] for i in valid_pred_indices]\n",
    "    valid_pred_polygons = [p['pixel_coords'] for p in valid_pred_grains]\n",
    "\n",
    "\n",
    "    gt_centroids = calculate_centroids(gt_polygons)\n",
    "    valid_pred_centroids = calculate_centroids(valid_pred_polygons)\n",
    "\n",
    "\n",
    "    # Filter out invalid centroids (NaNs, etc.) for KDTree\n",
    "    valid_gt_centroid_indices = [i for i, c in enumerate(gt_centroids) if not np.isnan(c).any()]\n",
    "    valid_pred_centroid_indices_in_valid_pred = [i for i, c in enumerate(valid_pred_centroids) if not np.isnan(c).any()] # Index within valid_pred_grains list\n",
    "\n",
    "\n",
    "    if len(valid_gt_centroid_indices) == 0 or len(valid_pred_centroid_indices_in_valid_pred) == 0:\n",
    "         print(\"Warning: No valid centroids found for matching.\")\n",
    "         # If no valid GT centroids, all predictions are unmatched\n",
    "         return {}, {}, all_pred_grains\n",
    "         # If no valid Pred centroids, all GT are unmatched, all preds are unmatched\n",
    "         # return {}, {}, all_pred_grains\n",
    "\n",
    "\n",
    "    final_gt_grains_for_matching = [valid_gt_grains[i] for i in valid_gt_centroid_indices]\n",
    "    final_gt_centroids = gt_centroids[valid_gt_centroid_indices]\n",
    "    final_gt_ids = [final_gt_grains_for_matching[i]['grain_id'] for i in range(len(final_gt_grains_for_matching))]\n",
    "\n",
    "    final_pred_grains_for_matching = [valid_pred_grains[i] for i in valid_pred_centroid_indices_in_valid_pred]\n",
    "    final_pred_centroids = valid_pred_centroids[valid_pred_centroid_indices_in_valid_pred]\n",
    "    # Map back to original all_pred_grains indices for the final matching predictions\n",
    "    final_pred_original_indices = [valid_pred_indices[i] for i in valid_pred_centroid_indices_in_valid_pred]\n",
    "\n",
    "\n",
    "    # Create KD-tree for efficient nearest neighbor search\n",
    "    tree = cKDTree(final_pred_centroids)\n",
    "\n",
    "\n",
    "    # Initialize containers\n",
    "    matches = {} # {gt_grain_id: original_pred_grain_index}\n",
    "    matched_pred_data = {} # {original_pred_grain_index: simplified_data}\n",
    "    # Keep track of which original prediction indices are used in matches\n",
    "    matched_pred_original_indices_set = set()\n",
    "\n",
    "    # Create masks for IoU calculation - only for the grains/preds with valid centroids/polygons\n",
    "    print(\"Creating masks for IoU calculation...\")\n",
    "    final_gt_polygons = [g['pixel_coords'] for g in final_gt_grains_for_matching]\n",
    "    final_pred_polygons = [p['pixel_coords'] for p in final_pred_grains_for_matching] # These are already filtered\n",
    "\n",
    "    gt_masks = create_mask_from_polygon_batch(final_gt_polygons, image_width, image_height)\n",
    "    pred_masks = create_mask_from_polygon_batch(final_pred_polygons, image_width, image_height)\n",
    "\n",
    "    if gt_masks.shape[0] == 0 or pred_masks.shape[0] == 0:\n",
    "         print(\"Warning: No valid masks generated for IoU calculation after filtering.\")\n",
    "         return {}, {}, all_pred_grains # If no masks, no matches possible\n",
    "\n",
    "    print(\"Starting matching process...\")\n",
    "    # Match grains based on centroid proximity and IoU\n",
    "    for i, gt_centroid in enumerate(final_gt_centroids):\n",
    "        gt_grain_id = final_gt_ids[i]\n",
    "\n",
    "        # Find nearby predictions using KDTree\n",
    "        nearby_final_pred_indices = tree.query_ball_point(gt_centroid, max_distance)\n",
    "\n",
    "        if not nearby_final_pred_indices:\n",
    "            continue # No nearby predictions within distance\n",
    "\n",
    "        # Map nearby indices (which are indices within final_pred_centroids/grains)\n",
    "        # back to their original indices in the all_pred_grains list\n",
    "        nearby_original_indices = [final_pred_original_indices[idx] for idx in nearby_final_pred_indices]\n",
    "\n",
    "\n",
    "        # Filter out predictions that have already been matched\n",
    "        unmatched_nearby_original_indices = [idx for idx in nearby_original_indices if idx not in matched_pred_original_indices_set]\n",
    "\n",
    "        if not unmatched_nearby_original_indices:\n",
    "             continue # All nearby predictions already matched or filtered\n",
    "\n",
    "        # Calculate IoUs for the remaining nearby, unmatched predictions\n",
    "        ious = []\n",
    "        original_indices_for_iou = []\n",
    "        for original_idx in unmatched_nearby_original_indices:\n",
    "             # Find the index of this original_idx within the final_pred_original_indices list\n",
    "             # This gives us the correct index to use with the `pred_masks` array\n",
    "             try:\n",
    "                  final_pred_mask_idx = final_pred_original_indices.index(original_idx)\n",
    "                  iou = np.sum(np.logical_and(gt_masks[i], pred_masks[final_pred_mask_idx])) / \\\n",
    "                        np.sum(np.logical_or(gt_masks[i], pred_masks[final_pred_mask_idx]))\n",
    "                  ious.append(iou)\n",
    "                  original_indices_for_iou.append(original_idx)\n",
    "             except ValueError:\n",
    "                  # This should not happen if logic is correct, but included as safeguard\n",
    "                  print(f\"Error: Original index {original_idx} not found in final_pred_original_indices. Skipping IoU calculation.\")\n",
    "                  continue\n",
    "\n",
    "\n",
    "        if not ious:\n",
    "             continue # No valid IoUs could be calculated\n",
    "\n",
    "        best_iou_relative_idx = np.argmax(ious)\n",
    "        best_iou = ious[best_iou_relative_idx]\n",
    "\n",
    "        if best_iou > iou_threshold:\n",
    "            # Get the original index of the best matching prediction\n",
    "            best_pred_original_idx = original_indices_for_iou[best_iou_relative_idx]\n",
    "\n",
    "            # This check is redundant if filtering worked correctly, but doesn't hurt\n",
    "            if best_pred_original_idx not in matched_pred_original_indices_set:\n",
    "                matches[gt_grain_id] = best_pred_original_idx\n",
    "                matched_pred_original_indices_set.add(best_pred_original_idx) # Mark this prediction as used\n",
    "\n",
    "                # Store simplified data for the matched prediction\n",
    "                # Use properties directly from the all_pred_grains list\n",
    "                matched_pred_data[best_pred_original_idx] = {\n",
    "                    'pixel_coords': all_pred_grains[best_pred_original_idx].get('pixel_coords', []),\n",
    "                    'area_true': all_pred_grains[best_pred_original_idx].get('area_true', 0.0),\n",
    "                    'length_true': all_pred_grains[best_pred_original_idx].get('length_true', 0.0),\n",
    "                    'area_pixels': all_pred_grains[best_pred_original_idx].get('area_pixels', 0.0), # Also store pixel area for context\n",
    "                    'length_pixels': all_pred_grains[best_pred_original_idx].get('length_pixels', 0.0), # Also store pixel length\n",
    "                }\n",
    "\n",
    "    # Determine unmatched predictions: any prediction in all_pred_grains whose original index\n",
    "    # is NOT in the matched_pred_original_indices_set.\n",
    "    unmatched_preds = [all_pred_grains[i] for i in range(len(all_pred_grains)) if i not in matched_pred_original_indices_set]\n",
    "\n",
    "    print(f\"Matching complete.\")\n",
    "    print(f\"  Total ground truth grains processed for matching: {len(final_gt_grains_for_matching)}\")\n",
    "    print(f\"  Total predictions processed for matching: {len(final_pred_grains_for_matching)}\")\n",
    "    print(f\"  Successfully matched GT grains: {len(matches)}\")\n",
    "    print(f\"  Matched predictions count: {len(matched_pred_original_indices_set)}\") # Should be equal to len(matches)\n",
    "    print(f\"  Unmatched predictions (FP) count: {len(unmatched_preds)}\")\n",
    "\n",
    "    return matches, matched_pred_data, unmatched_preds\n",
    "\n",
    "\n",
    "def calculate_metrics(gt_data: List[Dict],\n",
    "                      all_predictions: List[Dict],\n",
    "                      matches: Dict,\n",
    "                      unmatched_preds: List) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive segmentation performance metrics (Precision, Recall, F1).\n",
    "\n",
    "    Args:\n",
    "        gt_data: List of original ground truth grain dictionaries.\n",
    "        all_predictions: List of ALL original predicted grain dictionaries.\n",
    "        matches: Dictionary mapping GT grain_id to original prediction index.\n",
    "        unmatched_preds: List of prediction dictionaries that were not matched (False Positives).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the calculated metrics.\n",
    "    \"\"\"\n",
    "    total_gt = len(gt_data)\n",
    "    total_pred = len(all_predictions)\n",
    "    matched_count = len(matches) # Number of ground truth grains that found a match\n",
    "\n",
    "    # True Positives (TP): Number of ground truth grains that were correctly matched to a prediction.\n",
    "    # This is equivalent to the number of successful matches found.\n",
    "    tp = matched_count\n",
    "\n",
    "    # False Positives (FP): Predictions that did not match any ground truth grain.\n",
    "    # This is exactly the number of unmatched predictions.\n",
    "    fp = len(unmatched_preds)\n",
    "\n",
    "    # False Negatives (FN): Ground truth grains that did not find a match.\n",
    "    fn = total_gt - tp\n",
    "\n",
    "    # Calculate metrics\n",
    "    # Add handling for division by zero if denominators are zero\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"total_predictions\": total_pred,\n",
    "        \"total_ground_truth\": total_gt,\n",
    "        \"true_positives\": tp,\n",
    "        \"false_positives\": fp,\n",
    "        \"false_negatives\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"matched_gt_count\": matched_count, # Number of GT grains matched\n",
    "        \"matched_pred_count\": len(set(matches.values())), # Number of unique predictions that were matched (should equal matched_gt_count)\n",
    "        \"unmatched_pred_count\": fp # Same as false_positives\n",
    "    }\n",
    "\n",
    "\n",
    "def draw_matched_and_unmatched(image: np.ndarray, gt_data: List[Dict], all_pred_grains: List[Dict],\n",
    "                              matches: Dict, unmatched_preds: List) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draws contours of ground truth, matched predictions, and unmatched predictions\n",
    "    on the image for visualization.\n",
    "\n",
    "    Args:\n",
    "        image: Original image (NumPy array, HxWx3, RGB).\n",
    "        gt_data: List of ground truth grain dictionaries.\n",
    "        all_pred_grains: List of ALL predicted grain dictionaries.\n",
    "        matches: Dictionary mapping GT grain_id to prediction index.\n",
    "        unmatched_preds: List of prediction dictionaries that were not matched (FP).\n",
    "\n",
    "    Returns:\n",
    "        Image with colored contours.\n",
    "    \"\"\"\n",
    "    # Create a copy of the image and ensure it's in BGR for OpenCV drawing\n",
    "    # Using the same heuristic as draw_mask_contours\n",
    "    is_rgb = image.shape[-1] == 3 and np.max(image) > 1 and np.min(image) >= 0 and image[0,0,:].sum() > 100\n",
    "    if is_rgb:\n",
    "         result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    elif image.shape[-1] == 3:\n",
    "         result = image.copy()\n",
    "    else:\n",
    "         result = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Draw Ground Truth contours (Blue for unmatched, to identify FN)\n",
    "    # Iterate through GT data and check if its ID is in the keys of the 'matches' dictionary\n",
    "    matched_gt_ids = set(matches.keys())\n",
    "    for gt_grain in gt_data:\n",
    "        gt_id = gt_grain.get('grain_id')\n",
    "        contour_coords = gt_grain.get('pixel_coords', [])\n",
    "        if gt_id is not None and contour_coords and gt_id not in matched_gt_ids:\n",
    "             try:\n",
    "                  contour = np.array(contour_coords, dtype=np.int32)\n",
    "                  if len(contour) >= 3: # Ensure valid contour for drawing\n",
    "                       cv2.drawContours(result, [contour], -1, (255, 0, 0), 2) # Blue for unmatched GT (FN)\n",
    "             except Exception as e:\n",
    "                  print(f\"Warning: Could not draw contour for unmatched GT grain {gt_id}. Error: {e}\")\n",
    "\n",
    "\n",
    "    # Draw ALL Predicted contours\n",
    "    # Matched predictions in Green, Unmatched predictions in Red\n",
    "    # Iterate through the original list of all predictions using their index\n",
    "    matched_pred_original_indices_set = set(matches.values())\n",
    "\n",
    "    for i, pred in enumerate(all_pred_grains):\n",
    "        contour_coords = pred.get('pixel_coords', [])\n",
    "        if contour_coords:\n",
    "             try:\n",
    "                 contour = np.array(contour_coords, dtype=np.int32)\n",
    "                 if len(contour) >= 3: # Ensure valid contour for drawing\n",
    "                    if i in matched_pred_original_indices_set:\n",
    "                        # This prediction was matched to a GT\n",
    "                        cv2.drawContours(result, [contour], -1, (0, 255, 0), 2) # Green for Matched Predictions (TP)\n",
    "                    else:\n",
    "                        # This prediction was NOT matched (it's an unmatched_pred / FP)\n",
    "                        cv2.drawContours(result, [contour], -1, (0, 0, 255), 2) # Red for Unmatched Predictions (FP)\n",
    "             except Exception as e:\n",
    "                  print(f\"Warning: Could not draw contour for prediction index {i}. Error: {e}\")\n",
    "\n",
    "\n",
    "    # Convert back to RGB for matplotlib display\n",
    "    if is_rgb:\n",
    "        return cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "         return result # Return as BGR or grayscale-converted BGR\n",
    "\n",
    "\n",
    "def analyze_grain_distributions(gt_data: List[Dict],\n",
    "                                all_pred_grains: List[Dict],\n",
    "                                matched_pred_data: Dict) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes grain size (area) and length distributions.\n",
    "\n",
    "    Args:\n",
    "        gt_data: List of ground truth grain dictionaries.\n",
    "        all_pred_grains: List of ALL predicted grain dictionaries.\n",
    "        matched_pred_data: Dictionary of data for predictions that were matched.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - DataFrame with summary statistics.\n",
    "        - NumPy arrays of ground truth areas/lengths.\n",
    "        - NumPy arrays of all prediction areas/lengths.\n",
    "        - NumPy arrays of matched prediction areas/lengths.\n",
    "    \"\"\"\n",
    "    # Extract sizes and lengths, handling potential missing keys or zero values\n",
    "    gt_sizes = np.array([grain.get('area_true', 0.0) for grain in gt_data if grain.get('area_true', 0.0) > 0])\n",
    "    gt_lengths = np.array([grain.get('length_true', 0.0) for grain in gt_data if grain.get('length_true', 0.0) > 0])\n",
    "\n",
    "    # Use the pre-computed properties from get_sam_annotations_from_masks\n",
    "    all_pred_sizes = np.array([grain.get('area_true', 0.0) for grain in all_pred_grains if grain.get('area_true', 0.0) > 0])\n",
    "    all_pred_lengths = np.array([grain.get('length_true', 0.0) for grain in all_pred_grains if grain.get('length_true', 0.0) > 0])\n",
    "\n",
    "    # Extract sizes and lengths for *matched* predictions from the matched_pred_data dictionary\n",
    "    # The keys in matched_pred_data are the original indices from all_pred_grains\n",
    "    # The values are the simplified dictionaries {pixel_coords, area_true, length_true}\n",
    "    matched_pred_list = list(matched_pred_data.values()) # Convert dict values to a list\n",
    "    matched_pred_sizes = np.array([grain.get('area_true', 0.0) for grain in matched_pred_list if grain.get('area_true', 0.0) > 0])\n",
    "    matched_pred_lengths = np.array([grain.get('length_true', 0.0) for grain in matched_pred_list if grain.get('length_true', 0.0) > 0])\n",
    "\n",
    "\n",
    "    print(f\"\\nDistribution Data Counts:\")\n",
    "    print(f\"  Ground Truth grains: {len(gt_sizes)}\")\n",
    "    print(f\"  All predictions: {len(all_pred_sizes)}\")\n",
    "    print(f\"  Matched predictions: {len(matched_pred_sizes)}\") # Count of predictions that matched a GT\n",
    "\n",
    "    # Create summary DataFrame (align lengths for display if needed, or just show counts)\n",
    "    # Using Series.describe() is a good way to get standard stats\n",
    "    stats_dict = {}\n",
    "    if len(gt_sizes) > 0:\n",
    "         stats_dict['GT_Areas'] = pd.Series(gt_sizes).describe()\n",
    "         stats_dict['GT_Lengths'] = pd.Series(gt_lengths).describe()\n",
    "    if len(all_pred_sizes) > 0:\n",
    "        stats_dict['All_Pred_Areas'] = pd.Series(all_pred_sizes).describe()\n",
    "        stats_dict['All_Pred_Lengths'] = pd.Series(all_pred_lengths).describe()\n",
    "    if len(matched_pred_sizes) > 0:\n",
    "         stats_dict['Matched_Areas'] = pd.Series(matched_pred_sizes).describe()\n",
    "         stats_dict['Matched_Lengths'] = pd.Series(matched_pred_lengths).describe()\n",
    "\n",
    "    # Create a DataFrame from the statistics, handling case where some categories might be empty\n",
    "    if stats_dict:\n",
    "        # Create a DataFrame from the combined descriptions. 'index' will be the stats name (count, mean, etc.)\n",
    "        df_stats = pd.DataFrame(stats_dict)\n",
    "        # Ensure all standard stats are present, even if some are NaN\n",
    "        all_indices = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "        df_stats = df_stats.reindex(all_indices)\n",
    "    else:\n",
    "        df_stats = pd.DataFrame() # Empty DataFrame if no data\n",
    "\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df_stats)\n",
    "\n",
    "    # Visualization (only plot if there's data)\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # --- Histograms ---\n",
    "    # Use a function or loop to avoid repetition and handle empty data\n",
    "    def plot_histogram(ax, data, label, color, bins=30):\n",
    "        if data.size > 0:\n",
    "            ax.hist(data, bins=bins, alpha=0.6, label=label, density=True, color=color)\n",
    "\n",
    "    plot_histogram(axs[0, 0], gt_sizes, 'Ground Truth', 'blue')\n",
    "    plot_histogram(axs[0, 0], all_pred_sizes, 'All Predictions', 'orange')\n",
    "    plot_histogram(axs[0, 0], matched_pred_sizes, 'Matched Predictions', 'green')\n",
    "\n",
    "    plot_histogram(axs[0, 1], gt_lengths, 'Ground Truth', 'blue')\n",
    "    plot_histogram(axs[0, 1], all_pred_lengths, 'All Predictions', 'orange', bins=100) # More bins for length\n",
    "    plot_histogram(axs[0, 1], matched_pred_lengths, 'Matched Predictions', 'green')\n",
    "\n",
    "\n",
    "    # Set titles and scales for histograms\n",
    "    axs[0, 0].set_xscale('log')\n",
    "    axs[0, 0].set_title('Grain Size Distribution (Area)')\n",
    "    axs[0, 0].set_xlabel(f'Area ({SCALE_FACTOR*SCALE_FACTOR:.2f} unit)') # Adjusted unit label\n",
    "    axs[0, 0].set_ylabel('Density')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].set_xscale('log')\n",
    "    axs[0, 1].set_title('Grain Size Distribution (Length)')\n",
    "    axs[0, 1].set_xlabel(f'Length ({SCALE_FACTOR:.2f} unit)') # Adjusted unit label\n",
    "    axs[0, 1].set_ylabel('Density')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # --- CDFs ---\n",
    "    # Use a function or loop to avoid repetition and handle empty data\n",
    "    def plot_cdf(ax, data, label, color):\n",
    "        if data.size > 0:\n",
    "            ax.plot(np.sort(data),\n",
    "                    np.linspace(0, 1, len(data)),\n",
    "                    label=label, color=color)\n",
    "\n",
    "    plot_cdf(axs[1, 0], gt_sizes, 'Ground Truth', 'blue')\n",
    "    plot_cdf(axs[1, 0], all_pred_sizes, 'All Predictions', 'orange')\n",
    "    plot_cdf(axs[1, 0], matched_pred_sizes, 'Matched Predictions', 'green')\n",
    "\n",
    "    plot_cdf(axs[1, 1], gt_lengths, 'Ground Truth', 'blue')\n",
    "    plot_cdf(axs[1, 1], all_pred_lengths, 'All Predictions', 'orange')\n",
    "    plot_cdf(axs[1, 1], matched_pred_lengths, 'Matched Predictions', 'green')\n",
    "\n",
    "\n",
    "    # Set titles and scales for CDFs\n",
    "    axs[1, 0].set_xscale('log')\n",
    "    axs[1, 0].set_title('Cumulative Distribution (Area)')\n",
    "    axs[1, 0].set_xlabel(f'Area ({SCALE_FACTOR*SCALE_FACTOR:.2f} unit)') # Adjusted unit label\n",
    "    axs[1, 0].set_ylabel('Cumulative Probability')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].set_xscale('log')\n",
    "    axs[1, 1].set_title('Cumulative Distribution (Length)')\n",
    "    axs[1, 1].set_xlabel(f'Length ({SCALE_FACTOR:.2f} unit)') # Adjusted unit label\n",
    "    axs[1, 1].set_ylabel('Cumulative Probability')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return the data arrays for further analysis (e.g., KS statistic, NRMSE)\n",
    "    return df_stats, gt_sizes, all_pred_sizes, matched_pred_sizes, gt_lengths, all_pred_lengths, matched_pred_lengths\n",
    "\n",
    "\n",
    "def calculate_cumulative_data(sizes: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Calculate cumulative frequencies and percentiles for a sorted array.\"\"\"\n",
    "    if len(sizes) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    sorted_sizes = np.sort(sizes)\n",
    "    cumulative_freq = np.arange(1, len(sorted_sizes) + 1) / len(sorted_sizes)\n",
    "    return sorted_sizes, cumulative_freq\n",
    "\n",
    "\n",
    "def evaluate_distribution_similarity(gt_dist: np.ndarray, pred_dist: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the similarity between two distributions using KS statistic and NRMSE.\n",
    "\n",
    "    Args:\n",
    "        gt_dist: NumPy array of ground truth distribution values.\n",
    "        pred_dist: NumPy array of predicted distribution values.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing KS statistic and NRMSE.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Kolmogorov-Smirnov Test (compares empirical distribution functions)\n",
    "    # Lower KS statistic indicates greater similarity.\n",
    "    if len(gt_dist) > 1 and len(pred_dist) > 1:\n",
    "        try:\n",
    "            ks_statistic, ks_pvalue = ks_2samp(gt_dist, pred_dist)\n",
    "            metrics['ks_statistic'] = float(ks_statistic) # Ensure float\n",
    "            metrics['ks_pvalue'] = float(ks_pvalue) # Ensure float\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error computing KS statistic: {e}\")\n",
    "            metrics['ks_statistic'] = np.nan\n",
    "            metrics['ks_pvalue'] = np.nan\n",
    "    else:\n",
    "        metrics['ks_statistic'] = np.nan\n",
    "        metrics['ks_pvalue'] = np.nan\n",
    "        print(\"Warning: Cannot compute KS statistic for distributions with less than 2 samples.\")\n",
    "\n",
    "    # Normalized Root Mean Squared Error (NRMSE) on the cumulative distributions\n",
    "    # This requires comparing the cumulative distributions at a common set of points.\n",
    "    # A simple approach is to compare at percentiles.\n",
    "\n",
    "    if len(gt_dist) > 0 and len(pred_dist) > 0:\n",
    "        try:\n",
    "            # Using 101 points for percentiles (0% to 100%)\n",
    "            percentiles = np.linspace(0, 100, 101)\n",
    "            # Safely compute percentiles, handling empty arrays\n",
    "            gt_percentile_values = np.percentile(gt_dist, percentiles) if len(gt_dist) > 0 else np.zeros(len(percentiles))\n",
    "            pred_percentile_values = np.percentile(pred_dist, percentiles) if len(pred_dist) > 0 else np.zeros(len(percentiles))\n",
    "\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = np.sqrt(mean_squared_error(gt_percentile_values, pred_percentile_values))\n",
    "\n",
    "            # Normalize RMSE (common methods: by range, mean, or std dev of GT)\n",
    "            # Normalizing by the range of the GT is common for size distributions\n",
    "            gt_range = np.max(gt_dist) - np.min(gt_dist) if len(gt_dist) > 1 else (np.mean(gt_dist) if len(gt_dist) == 1 else 1.0)\n",
    "            nrmse_range = (rmse / gt_range) if gt_range != 0 else np.inf\n",
    "\n",
    "            # Normalizing by the mean of the GT is another common method (often expressed as %)\n",
    "            gt_mean = np.mean(gt_dist) if len(gt_dist) > 0 else 1.0\n",
    "            nrmse_mean = (rmse / gt_mean) if gt_mean != 0 else np.inf\n",
    "\n",
    "\n",
    "            metrics['nrmse_range'] = float(nrmse_range) # Ensure float\n",
    "            metrics['nrmse_mean'] = float(nrmse_mean)   # Ensure float (as a fraction, multiply by 100 for %)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error calculating NRMSE: {e}\")\n",
    "             metrics['nrmse_range'] = np.nan\n",
    "             metrics['nrmse_mean'] = np.nan\n",
    "    else:\n",
    "        metrics['nrmse_range'] = np.nan\n",
    "        metrics['nrmse_mean'] = np.nan\n",
    "        print(\"Warning: Cannot compute NRMSE for empty distributions.\")\n",
    "\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63633806",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Automatic Mask Generation\n",
    "\n",
    "Initialize the `SamAutomaticMaskGenerator` class corresponding to the loaded model with specified parameters and generate masks for the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbf814",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check if the necessary generator class was found based on the selected variant\n",
    "if SamAutomaticMaskGeneratorClass is None:\n",
    "     raise RuntimeError(f\"SamAutomaticMaskGenerator class not available for MODEL_VARIANT: {MODEL_VARIANT}. Please check imports and configuration.\")\n",
    "\n",
    "print(f\"Initializing SamAutomaticMaskGenerator for {MODEL_VARIANT}...\")\n",
    "mask_generator = SamAutomaticMaskGeneratorClass(model=sam, **AMBG_PARAMS)\n",
    "print(\"Mask generator initialized.\")\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate masks\n",
    "# The generator expects a HxWx3 uint8 NumPy array (RGB or BGR depending on model training).\n",
    "# We are using the `image_rgb` NumPy array directly.\n",
    "print(\"Generating masks...\")\n",
    "masks = mask_generator.generate(image_rgb)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Mask generation took {execution_time:.4f} seconds\")\n",
    "print(f\"Number of raw masks generated: {len(masks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164001a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Visualize Results\n",
    "\n",
    "Display the original image with the generated masks and their contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize masks overlay\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image_rgb) # Use the RGB image for display\n",
    "show_anns(masks)\n",
    "plt.title(f'{MODEL_VARIANT} Masks Overlay')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualize contours\n",
    "# Use the original BGR image for cv2.drawContours, then convert back to RGB for matplotlib\n",
    "contoured_image = draw_mask_contours(image_bgr, masks, color=(0, 255, 0), thickness=2) \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(contoured_image)\n",
    "plt.title(f'{MODEL_VARIANT} Mask Contours')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d18b3",
   "metadata": {},
   "source": [
    "\n",
    "# Process Masks and Load Ground Truth\n",
    "\n",
    "Convert the generated masks into structured grain data and load the ground truth annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process SAM masks into grain annotations\n",
    "print(\"Processing SAM masks to extract grain properties...\")\n",
    "# The get_sam_annotations_from_masks function uses AMBG_PARAMS internally for filtering,\n",
    "# so pass it implicitly via the global scope, or pass specific params if preferred.\n",
    "sam_annotations = get_sam_annotations_from_masks(masks, SCALE_FACTOR, image_width, image_height, coverage_threshold=0.95) # Using a default coverage threshold\n",
    "print(f\"Extracted {len(sam_annotations)} potential grain annotations from SAM masks.\")\n",
    "\n",
    "# Load Ground Truth data\n",
    "print(f\"Loading ground truth annotations from {GROUND_TRUTH_ANNOTATION_PATH}...\")\n",
    "if not os.path.exists(GROUND_TRUTH_ANNOTATION_PATH):\n",
    "    print(f\"Warning: Ground truth annotation file not found at {GROUND_TRUTH_ANNOTATION_PATH}.\")\n",
    "    print(\"Skipping evaluation against ground truth.\")\n",
    "    gt_data = [] # Set to empty list to skip evaluation\n",
    "else:\n",
    "    try:\n",
    "        with open(GROUND_TRUTH_ANNOTATION_PATH, 'r') as f:\n",
    "            gt_data = json.load(f)\n",
    "        print(f\"Loaded {len(gt_data)} ground truth grain annotations.\")\n",
    "\n",
    "        # Basic check for expected keys in GT data\n",
    "        if gt_data and ('pixel_coords' not in gt_data[0] or 'grain_id' not in gt_data[0]):\n",
    "             print(\"Warning: Ground truth data might not be in the expected format ('pixel_coords', 'grain_id').\")\n",
    "             print(\"Attempting to add 'grain_id' if missing...\")\n",
    "             # Attempt to add a simple grain_id if missing, assuming list of grain dicts\n",
    "             if 'grain_id' not in gt_data[0]:\n",
    "                  for i, grain in enumerate(gt_data):\n",
    "                       grain['grain_id'] = i + 1\n",
    "             # Further validation could be added here if needed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ground truth JSON from {GROUND_TRUTH_ANNOTATION_PATH}: {e}\")\n",
    "        print(\"Skipping evaluation against ground truth.\")\n",
    "        gt_data = [] # Set to empty list to skip evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a87b2",
   "metadata": {},
   "source": [
    "# Evaluate Segmentation Matching Performance\n",
    "\n",
    "Match predicted grains to ground truth based on spatial overlap and calculate precision, recall, and F1-score.\n",
    "\n",
    "This step is only performed if ground truth data was successfully loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cacdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if gt_data:\n",
    "    # Perform grain matching\n",
    "    # Use the full list of SAM annotations (sam_annotations) and the loaded ground truth (gt_data)\n",
    "    print(\"\\nPerforming grain matching for evaluation...\")\n",
    "    matches, matched_pred_data, unmatched_preds = fast_match_grains(\n",
    "        gt_data,\n",
    "        sam_annotations,\n",
    "        image_width,\n",
    "        image_height,\n",
    "        iou_threshold=IOU_THRESHOLD,\n",
    "        max_distance=CENTROID_MATCH_DISTANCE\n",
    "    )\n",
    "    print(\"Matching complete.\")\n",
    "\n",
    "    # Calculate segmentation metrics\n",
    "    metrics = calculate_metrics(gt_data, sam_annotations, matches, unmatched_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nSegmentation Performance Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")\n",
    "        else:\n",
    "             print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping segmentation matching evaluation: Ground truth data not loaded.\")\n",
    "    matches = {} # Ensure matches dictionary is empty if no GT\n",
    "    matched_pred_data = {} # Ensure matched_pred_data is empty if no GT\n",
    "    unmatched_preds = sam_annotations # If no GT, all predictions are effectively 'unmatched' for this metric\n",
    "\n",
    "    # Create a placeholder metrics dictionary with NaN values\n",
    "    metrics = {\n",
    "        \"total_predictions\": len(sam_annotations),\n",
    "        \"total_ground_truth\": len(gt_data), # Will be 0\n",
    "        \"true_positives\": 0,\n",
    "        \"false_positives\": len(sam_annotations), # All predictions are FP if no GT\n",
    "        \"false_negatives\": len(gt_data), # All GT are FN if no preds (or no GT loaded)\n",
    "        \"precision\": np.nan,\n",
    "        \"recall\": np.nan,\n",
    "        \"f1_score\": np.nan,\n",
    "        \"matched_gt_count\": 0,\n",
    "        \"matched_pred_count\": 0,\n",
    "        \"unmatched_pred_count\": len(sam_annotations)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22b7be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "## Visualize Matching Results\n",
    "# \n",
    "# Display the image highlighting matched and unmatched grains. This step is only performed if ground truth data was successfully loaded, as it requires knowing which predictions correspond to ground truth grains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c014e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "if gt_data:\n",
    "    # Visualize matched vs unmatched contours\n",
    "    # GT unmatched (FN) in Blue, Matched predictions (TP) in Green, Unmatched predictions (FP) in Red\n",
    "    print(\"\\nVisualizing matched and unmatched grains...\")\n",
    "    matched_unmatched_image = draw_matched_and_unmatched(\n",
    "        image_rgb, # Use RGB image for matplotlib display\n",
    "        gt_data,\n",
    "        sam_annotations, # Pass all_pred_grains\n",
    "        matches,\n",
    "        unmatched_preds\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(matched_unmatched_image)\n",
    "    plt.title(f'{MODEL_VARIANT} Matching Results: GT Unmatched (Blue), Matched Pred (Green), Unmatched Pred (Red)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping matching visualization: Ground truth data not loaded.\")\n",
    "    # Optionally, visualize *all* predicted contours in a single color if no GT\n",
    "    print(\"Visualizing all predicted contours instead.\")\n",
    "    all_pred_contoured_image = draw_mask_contours(image_bgr, masks, color=(0, 165, 255), thickness=2) # Orange contours\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(all_pred_contoured_image)\n",
    "    plt.title(f'{MODEL_VARIANT} All Predicted Contours (No GT Loaded)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd4781",
   "metadata": {},
   "source": [
    "\n",
    "# Analyze Grain Size Distributions\n",
    "\n",
    "Compare the grain size (area) and length distributions from ground truth, all predictions, and matched predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97132a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nAnalyzing grain size distributions...\")\n",
    "df_stats, gt_sizes, all_pred_sizes, matched_pred_sizes, gt_lengths, all_pred_lengths, matched_pred_lengths = analyze_grain_distributions(\n",
    "    gt_data, sam_annotations, matched_pred_data\n",
    ")\n",
    "\n",
    "# Evaluate distribution similarity using KS statistic and NRMSE (only if GT and matched predictions exist)\n",
    "distribution_metrics = {}\n",
    "if len(gt_sizes) > 1 and len(matched_pred_sizes) > 1:\n",
    "    print(\"\\nEvaluating distribution similarity (Matched Predictions vs. Ground Truth):\")\n",
    "    area_dist_metrics = evaluate_distribution_similarity(gt_sizes, matched_pred_sizes)\n",
    "    length_dist_metrics = evaluate_distribution_similarity(gt_lengths, matched_pred_lengths)\n",
    "\n",
    "    print(\"\\nArea Distribution Metrics:\")\n",
    "    for key, value in area_dist_metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key.replace('_', ' ').title()}: {value:.4f}\")\n",
    "        else:\n",
    "             print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "    print(\"\\nLength Distribution Metrics:\")\n",
    "    for key, value in length_dist_metrics.items():\n",
    "         if isinstance(value, float):\n",
    "              print(f\"  {key.replace('_', ' ').title()}: {value:.4f}\")\n",
    "         else:\n",
    "              print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "    # Combine all distribution metrics into a single dictionary for saving\n",
    "    distribution_metrics = {\n",
    "        'Area_KS_Statistic': area_dist_metrics.get('ks_statistic', np.nan),\n",
    "        'Area_KS_PValue': area_dist_metrics.get('ks_pvalue', np.nan),\n",
    "        'Area_NRMSE_Range': area_dist_metrics.get('nrmse_range', np.nan),\n",
    "        'Area_NRMSE_Mean': area_dist_metrics.get('nrmse_mean', np.nan),\n",
    "        'Length_KS_Statistic': length_dist_metrics.get('ks_statistic', np.nan),\n",
    "        'Length_KS_PValue': length_dist_metrics.get('ks_pvalue', np.nan),\n",
    "        'Length_NRMSE_Range': length_dist_metrics.get('nrmse_range', np.nan),\n",
    "        'Length_NRMSE_Mean': length_dist_metrics.get('nrmse_mean', np.nan),\n",
    "    }\n",
    "else:\n",
    "     print(\"\\nSkipping distribution similarity evaluation: Not enough data in Ground Truth or Matched Predictions.\")\n",
    "     distribution_metrics = { # Placeholder with NaN values\n",
    "         'Area_KS_Statistic': np.nan, 'Area_KS_PValue': np.nan, 'Area_NRMSE_Range': np.nan, 'Area_NRMSE_Mean': np.nan,\n",
    "         'Length_KS_Statistic': np.nan, 'Length_KS_PValue': np.nan, 'Length_NRMSE_Range': np.nan, 'Length_NRMSE_Mean': np.nan,\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10065f4b",
   "metadata": {},
   "source": [
    "\n",
    "# Save Results\n",
    "\n",
    "Save the calculated metrics and detailed distribution data to CSV and Excel files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0131fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save segmentation metrics (always save, even if empty/NaN)\n",
    "metrics_output_path = os.path.join(OUTPUT_RESULTS_DIR, \"segmentation_metrics.csv\")\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(metrics_output_path, index=False)\n",
    "print(f\"\\nSegmentation metrics saved to: {metrics_output_path}\")\n",
    "\n",
    "\n",
    "# Save distribution similarity metrics (always save, even if empty/NaN)\n",
    "dist_metrics_output_path = os.path.join(OUTPUT_RESULTS_DIR, \"distribution_similarity_metrics.csv\")\n",
    "dist_metrics_df = pd.DataFrame([distribution_metrics])\n",
    "dist_metrics_df.to_csv(dist_metrics_output_path, index=False)\n",
    "print(f\"Distribution similarity metrics saved to: {dist_metrics_output_path}\")\n",
    "\n",
    "\n",
    "# Save detailed distribution data (raw and cumulative)\n",
    "output_distribution_file = os.path.join(OUTPUT_RESULTS_DIR, 'grain_distributions_comprehensive.xlsx')\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(output_distribution_file) as writer:\n",
    "        # Raw distributions (handle cases where arrays might be empty)\n",
    "        if gt_sizes.size > 0 or gt_lengths.size > 0:\n",
    "             gt_raw_df = pd.DataFrame()\n",
    "             if gt_sizes.size > 0: gt_raw_df['Ground_Truth_Areas'] = gt_sizes\n",
    "             if gt_lengths.size > 0: gt_raw_df['Ground_Truth_Lengths'] = gt_lengths\n",
    "             if not gt_raw_df.empty:\n",
    "                  gt_raw_df.to_excel(writer, sheet_name='Ground_Truth_Raw', index=False)\n",
    "             else:\n",
    "                  print(\"Warning: Ground Truth Raw data is empty, skipping sheet.\")\n",
    "\n",
    "\n",
    "        if all_pred_sizes.size > 0 or all_pred_lengths.size > 0:\n",
    "             all_pred_raw_df = pd.DataFrame()\n",
    "             if all_pred_sizes.size > 0: all_pred_raw_df['All_Predictions_Areas'] = all_pred_sizes\n",
    "             if all_pred_lengths.size > 0: all_pred_raw_df['All_Predictions_Lengths'] = all_pred_lengths\n",
    "             if not all_pred_raw_df.empty:\n",
    "                  all_pred_raw_df.to_excel(writer, sheet_name='All_Predictions_Raw', index=False)\n",
    "             else:\n",
    "                  print(\"Warning: All Predictions Raw data is empty, skipping sheet.\")\n",
    "\n",
    "        if matched_pred_sizes.size > 0 or matched_pred_lengths.size > 0:\n",
    "             matched_raw_df = pd.DataFrame()\n",
    "             if matched_pred_sizes.size > 0: matched_raw_df['Matched_Predictions_Areas'] = matched_pred_sizes\n",
    "             if matched_pred_lengths.size > 0: matched_raw_df['Matched_Predictions_Lengths'] = matched_pred_lengths\n",
    "             if not matched_raw_df.empty:\n",
    "                  matched_raw_df.to_excel(writer, sheet_name='Matched_Predictions_Raw', index=False)\n",
    "             else:\n",
    "                  print(\"Warning: Matched Predictions Raw data is empty, skipping sheet.\")\n",
    "\n",
    "\n",
    "        # Calculate and save cumulative distributions\n",
    "        gt_area_sorted, gt_area_cum = calculate_cumulative_data(gt_sizes)\n",
    "        gt_length_sorted, gt_length_cum = calculate_cumulative_data(gt_lengths)\n",
    "        all_pred_area_sorted, all_pred_area_cum = calculate_cumulative_data(all_pred_sizes)\n",
    "        all_pred_length_sorted, all_pred_length_cum = calculate_cumulative_data(all_pred_lengths)\n",
    "        matched_area_sorted, matched_area_cum = calculate_cumulative_data(matched_pred_sizes)\n",
    "        matched_length_sorted, matched_length_cum = calculate_cumulative_data(matched_pred_lengths)\n",
    "\n",
    "        if gt_area_sorted.size > 0 or gt_length_sorted.size > 0:\n",
    "            gt_cum_df = pd.DataFrame()\n",
    "            if gt_area_sorted.size > 0:\n",
    "                 gt_cum_df['Area'] = gt_area_sorted\n",
    "                 gt_cum_df['Area_Cumulative'] = gt_area_cum\n",
    "            if gt_length_sorted.size > 0:\n",
    "                 gt_cum_df['Length'] = gt_length_sorted\n",
    "                 gt_cum_df['Length_Cumulative'] = gt_length_cum\n",
    "            if not gt_cum_df.empty:\n",
    "                 gt_cum_df.to_excel(writer, sheet_name='Ground_Truth_Cumulative', index=False)\n",
    "            else:\n",
    "                 print(\"Warning: Ground Truth Cumulative data is empty, skipping sheet.\")\n",
    "\n",
    "\n",
    "        if all_pred_area_sorted.size > 0 or all_pred_length_sorted.size > 0:\n",
    "             all_pred_cum_df = pd.DataFrame()\n",
    "             if all_pred_area_sorted.size > 0:\n",
    "                  all_pred_cum_df['Area'] = all_pred_area_sorted\n",
    "                  all_pred_cum_df['Area_Cumulative'] = all_pred_area_cum\n",
    "             if all_pred_length_sorted.size > 0:\n",
    "                  all_pred_cum_df['Length'] = all_pred_length_sorted\n",
    "                  all_pred_cum_df['Length_Cumulative'] = all_pred_length_cum\n",
    "             if not all_pred_cum_df.empty:\n",
    "                 all_pred_cum_df.to_excel(writer, sheet_name='All_Predictions_Cumulative', index=False)\n",
    "             else:\n",
    "                  print(\"Warning: All Predictions Cumulative data is empty, skipping sheet.\")\n",
    "\n",
    "\n",
    "        if matched_area_sorted.size > 0 or matched_length_sorted.size > 0:\n",
    "            matched_cum_df = pd.DataFrame()\n",
    "            if matched_area_sorted.size > 0:\n",
    "                 matched_cum_df['Area'] = matched_area_sorted\n",
    "                 matched_cum_df['Area_Cumulative'] = matched_area_cum\n",
    "            if matched_length_sorted.size > 0:\n",
    "                 matched_cum_df['Length'] = matched_length_sorted\n",
    "                 matched_cum_df['Length_Cumulative'] = matched_length_cum\n",
    "            if not matched_cum_df.empty:\n",
    "                 matched_cum_df.to_excel(writer, sheet_name='Matched_Cumulative', index=False)\n",
    "            else:\n",
    "                 print(\"Warning: Matched Cumulative data is empty, skipping sheet.\")\n",
    "\n",
    "\n",
    "        # Save statistics (using the df_stats DataFrame computed earlier)\n",
    "        if not df_stats.empty:\n",
    "             # Ensure 'Metric' column is the first column\n",
    "             stats_df_to_save = df_stats.copy()\n",
    "             stats_df_to_save.reset_index(inplace=True)\n",
    "             stats_df_to_save.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "             stats_df_to_save.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "        else:\n",
    "             print(\"Warning: No statistics data to save.\")\n",
    "\n",
    "\n",
    "        # Save Percentiles (handle cases where arrays might be empty)\n",
    "        percentiles = [0, 10, 25, 50, 75, 90, 100]\n",
    "        percentile_data = {'Percentile': percentiles}\n",
    "\n",
    "        if gt_sizes.size > 0:\n",
    "             percentile_data['GT_Areas'] = np.percentile(gt_sizes, percentiles)\n",
    "             percentile_data['GT_Lengths'] = np.percentile(gt_lengths, percentiles)\n",
    "        if all_pred_sizes.size > 0:\n",
    "             percentile_data['All_Pred_Areas'] = np.percentile(all_pred_sizes, percentiles)\n",
    "             percentile_data['All_Pred_Lengths'] = np.percentile(all_pred_lengths, percentiles)\n",
    "        if matched_pred_sizes.size > 0:\n",
    "             percentile_data['Matched_Areas'] = np.percentile(matched_pred_sizes, percentiles)\n",
    "             percentile_data['Matched_Lengths'] = np.percentile(matched_pred_lengths, percentiles)\n",
    "\n",
    "        # Check if any percentile columns were added beyond just 'Percentile'\n",
    "        if len(percentile_data) > 1:\n",
    "            pd.DataFrame(percentile_data).to_excel(writer, sheet_name='Percentiles', index=False)\n",
    "        else:\n",
    "            print(\"Warning: No percentile data to save.\")\n",
    "\n",
    "\n",
    "    print(f\"Comprehensive distribution data saved to '{output_distribution_file}'\")\n",
    "\n",
    "except ImportError:\n",
    "     print(\"\\nError: Required library 'openpyxl' not found.\")\n",
    "     print(\"Please install it to save results to Excel: pip install openpyxl\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nError saving comprehensive distribution data to Excel: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153ba09",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusion\n",
    "\n",
    "This notebook provides a complete workflow from mask generation using a SAM variant (demonstrated with MobileSAM) to quantitative evaluation of segmentation performance and grain size distribution accuracy against ground truth. It serves as a base for users to apply and evaluate different lightweight SAM models for automated petrographic analysis. Users can adapt the configuration parameters and model loading logic to experiment with various variants and integrate this code into larger petrographic analysis pipelines.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
